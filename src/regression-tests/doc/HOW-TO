HOW-TO

This document describes how to use this regression test system.

The regression tests are organized around goals. Each goal has its own
directory under regression-tests/goals, and each goal directory
contains (or should contain) a README file explaining the goal in
question.

Two goal directories are seq-hof and par-ptup. Their README files
(subject to improvement, of course) are currently

  Tests of handwritten versions of common functional programming
  combinators like map and filter.

and

  Some tests of Manticore programs that use parallel tuples.

respectively.

ADDING NEW GOALS AND TESTS

To add a new test to the batch, first peruse the existing goal
directories and their READMEs to see if your test fits into an
existing category. If not, create a new directory under goals and a
corresponding README.

To create a new individual test, you must create two files: one called
program.pml, and one called program.ok. The latter contains the expected
results of the former.

For the sake of argument, assume we'd like to test multiplication on
parallel tuples. First we note this belongs in the existing directory
goals/par-ptup. We save the following two files into par-ptup:

  mult.pml

    fun mult (m:int, n:int) = m*n 
    val prod = mult (| 2, 3 |)
    val _ = Print.printLn (itos prod)

  mult.ok

    6

Then you can simply use the run-tests script (instructions
follow). The program will pick up all the programs inside directories
inside regression-tests/goals, so no further action needs to be taken.

Programs without observable effects -- in other words, those whose ok
files are empty -- are not recommended for tests, although they will
flow through the testing process without trouble.

If there is no "ok file" for a given test, the user will be given a
warning at the console when the tests are run, and the test result and
corresponding HTML report will indicate a missing ok file for the test
in question.

RUNNING THE TESTS

There is a script in regression-tests/bin called run-tests. Executing
it will populate regression-tests/reports/current/results.html with
new test results. It will also write quasi-XML result files into the
regression-tests/reports/archive.

The run-tests command-line tool has two options.

  -m (--mc) PATH           path to the Manticore compiler
  -c (--local-copy) FILE   a location to write the HTML report to

If no Manticore compiler is specified with the m option, the system
assumes that "mc" is in your path and juts calls it straight.

The latter option is the name of a file where you'd like the test
results file to go in addition to the default location given
above. For example, I (Adam) run this command as follows:

  ./run-tests -c ~/MCResults/results.html

Thanks to NFS, I am then able to view the results with a browser on my
local machine, which can't directly run the Manticore compiler (and
conversely, the machine running the Manticore compiler can't run a
browser for me).

Note you'll want a stylesheet results.css to live in the directory
with the generated file. (It will be legible even without it.)  You
can grab a copy of results.css from regression-tests/reports/. Edit
that stylesheet to suit you and store it locally if the given one is
not to your liking.

TEST HISTORY 

The HTML report generated by the test run includes, for each test
program, the current result and as many as four most recent test
results, if they exist. This way one can get a sense of whether the
compiler is at present better or worse than previous incarnations.

Note the contents of reports/archive are intended to exist on a
per-user basis, since users will want to run tests before checking in
code to svn. As such a "collective archive" would not make any sense.
As a result, the history presented in the regression test results is
to be understood as a _personal history_ which may or may not coincide
with the histories of other users.

FRAGILITY

If the name (i.e., filename) of a test is changed, then its ties to
previous test runs will be severed. More concretely, if there is a
test called map.pml whose filename is changed to pair-map.pml, then
the system will not be able to relate its current run to previous
runs. One could imagine building a more robust infrastructure that
addressed this weakness, but I chose not to invest the time. Along
similar lines, if the content of a test is changed, the testing
facilities will not indicate or "know" that a test is not testing
exactly what it used to.

Therefore, it should be considered best practice to add a test once
and only once to the batch, and leave its name and contents alone;
that is, add new, freshly-named tests in favor of modifying old ones.

KNOWN ISSUES

- BUG: The system checks the manticore revision, but *doesn't* make
sure the build of the compiler corresponds.

- Bug or feature? There is no way to test a program that should crash.

- It might be worth considering whether backends other than HTML would
be desirable.

- Paths and filenames are not yet all abstracted away from particular
syntactic conventions. i.e., I should be using OS.Path.joinBaseExt
instead of (b ^ "." ^ e).

--

Adam Shaw
Fall 2008
